name: ✳️ Upload Flyway files to S3

on:
  workflow_call:
    inputs:
      environment:
        type: string
        required: true
      skip-upload-libraries:
        type: boolean
        required: false
        default: true
  workflow_dispatch:
    inputs:
      environment:
        type: choice
        required: true
        description: AWS environment
        options: [DEV, BUILD, STAGING, INTEGRATION, PRODUCTION, PRODUCTION-PREVIEW]
      skip-upload-libraries:
        type: boolean
        required: false
        description: Skip uploading flyway tar and redshift jar as it is slow to do so and it only needs to be done if they have changed
        default: true

jobs:
  validate-environment:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5
      - name: Validate input environment
        run: scripts/validate-environment.sh ${{ inputs.environment }}

  upload-to-s3:
    needs: [validate-environment]
    # These permissions are needed to interact with GitHub's OIDC Token endpoint (enabling the aws-actions/configure-aws-credentials action)
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5
        with:
          lfs: true
      - name: Assume AWS GitHub actions role
        uses: aws-actions/configure-aws-credentials@00943011d9042930efac3dcd3a170e4273319bc8 # v4
        with:
          aws-region: eu-west-2
          role-to-assume: ${{ secrets.FLYWAY_FILES_UPLOAD_ROLE_ARN }}
      - name: Upload flyway files to S3
        run: |
          REGION="eu-west-2"
          FILES_ROOT="redshift-scripts/flyway"
          S3_BUCKET="s3://$(echo "${{ inputs.environment }}" | tr '[:upper:]' '[:lower:]')-dap-flyway-files"
          EXCLUDE=$(if [ ${{ inputs.skip-upload-libraries }} == "true" ]; then echo "lib/*"; else echo ""; fi)

          echo "Uploading contents of $FILES_ROOT to bucket $S3_BUCKET (skip-upload-libraries: ${{ inputs.skip-upload-libraries }})"
          aws --region="$REGION" s3 rm "$S3_BUCKET" --recursive --exclude "$EXCLUDE"
          aws --region="$REGION" s3 cp "$FILES_ROOT" "$S3_BUCKET" --recursive --exclude "$EXCLUDE" --exclude "README.md"
